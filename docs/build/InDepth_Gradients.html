

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>In depth: Gradients &mdash; simplenlopt 1.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Curve Fitting" href="Curve_Fitting.html" />
    <link rel="prev" title="Global Optimization" href="Global_Opt.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> simplenlopt
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="Constrained_Optimization.html">Constrained optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="Global_Opt.html">Global Optimization</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">In depth: Gradients</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#jac=callable">jac=callable</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jac-=-True">jac = True</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jac=‘nlopt’">jac=‘nlopt’</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jac-=-‘3-point’/‘2-point’">jac = ‘3-point’/‘2-point’</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Autodiff">Autodiff</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Curve_Fitting.html">Curve Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="simplenlopt.html">simplenlopt package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">simplenlopt</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>In depth: Gradients</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/InDepth_Gradients.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="In-depth:-Gradients">
<h1>In depth: Gradients<a class="headerlink" href="#In-depth:-Gradients" title="Permalink to this headline">¶</a></h1>
<p>This tutorial shows how to supply gradient information about an objective to simplenlopt in SciPy or NLopt style. One example for modern automatic differentiation via the external package autograd is also included. The studied optimization problem is again the Rosenbrock function. Its objective and partial derivatives are given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
f(x, y) &amp; =(1-x)^2+100(y-x^2)^2\\
\frac{\partial f}{\partial x} &amp;=-2(1-x)-400x(y-x^2) \\
\frac{\partial f}{\partial y} &amp;=200(y-x^2)
\end{align}\end{split}\]</div>
<div class="section" id="jac=callable">
<h2>jac=callable<a class="headerlink" href="#jac=callable" title="Permalink to this headline">¶</a></h2>
<p>The easiest case which is also shown in the quickstart example. Objective and gradient are supplied as two individual functions:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">simplenlopt</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>

<span class="k">def</span> <span class="nf">rosenbrock</span><span class="p">(</span><span class="n">pos</span><span class="p">):</span>

    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pos</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="k">def</span> <span class="nf">rosenbrock_grad</span><span class="p">(</span><span class="n">pos</span><span class="p">):</span>

    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pos</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">-</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">400</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">dy</span> <span class="o">=</span> <span class="mi">200</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">])</span>

<span class="n">x0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.25</span><span class="p">])</span>
<span class="o">%</span><span class="k">timeit</span> -n 1000 res = simplenlopt.minimize(rosenbrock, x0, jac = rosenbrock_grad)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2.33 ms ± 51.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</pre></div></div>
</div>
</div>
<div class="section" id="jac-=-True">
<h2>jac = True<a class="headerlink" href="#jac-=-True" title="Permalink to this headline">¶</a></h2>
<p>Taking another look at the objective and its partial derivaties you can see that the expression in the brackets appear in both the objective and the partial derivatives. If both are calculated in individual functions, these terms are unnecessarily recomputed. This can be avoided by supplying both the objective and its gradient in one function. That the objective also contains the gradient information, is indicated by setting jac=True. Let’s see how this works and how it affects the performance.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">rosenbrock_incl_grad</span><span class="p">(</span><span class="n">pos</span><span class="p">):</span>

    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pos</span>
    <span class="n">first_bracket</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">x</span>
    <span class="n">second_bracket</span> <span class="o">=</span> <span class="n">y</span><span class="o">-</span><span class="n">x</span><span class="o">*</span><span class="n">x</span>

    <span class="n">obj</span> <span class="o">=</span> <span class="n">first_bracket</span><span class="o">*</span><span class="n">first_bracket</span><span class="o">+</span><span class="mi">100</span><span class="o">*</span><span class="n">second_bracket</span><span class="o">*</span><span class="n">second_bracket</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">first_bracket</span><span class="o">-</span><span class="mi">400</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="n">second_bracket</span>
    <span class="n">dy</span> <span class="o">=</span> <span class="mi">200</span> <span class="o">*</span> <span class="n">second_bracket</span>

    <span class="k">return</span> <span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">])</span>

<span class="o">%</span><span class="k">timeit</span> -n 1000 res = simplenlopt.minimize(rosenbrock_incl_grad, x0, jac = True)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2.25 ms ± 44.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</pre></div></div>
</div>
<p>We see a small performance improvement. For more complicated objective functions, the performance gains can be massive though it repeated computations can be avoided.</p>
</div>
<div class="section" id="jac=‘nlopt’">
<h2>jac=‘nlopt’<a class="headerlink" href="#jac=‘nlopt’" title="Permalink to this headline">¶</a></h2>
<p>This flag is mostly for former NLopt users. It indicates that the objective and its gradient are supplied in vanilla <a class="reference external" href="https://nlopt.readthedocs.io/en/latest/NLopt_Tutorial/#example-in-python">NLopt style</a>. NLopt requires another signature for the objective: <code class="docutils literal notranslate"><span class="pre">f(x,</span> <span class="pre">grad)</span></code> instead of <code class="docutils literal notranslate"><span class="pre">f(x)</span></code>. The gradient given by grad is given by a NumPy array which must be replaced in-place. For the Rosenbrock example this looks like:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">rosenbrock_nlopt_style</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>

    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pos</span>
    <span class="n">first_bracket</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">x</span>
    <span class="n">second_bracket</span> <span class="o">=</span> <span class="n">y</span><span class="o">-</span><span class="n">x</span><span class="o">*</span><span class="n">x</span>

    <span class="n">obj</span> <span class="o">=</span> <span class="n">first_bracket</span><span class="o">*</span><span class="n">first_bracket</span><span class="o">+</span><span class="mi">100</span><span class="o">*</span><span class="n">second_bracket</span><span class="o">*</span><span class="n">second_bracket</span>

    <span class="k">if</span> <span class="n">grad</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>

        <span class="n">dx</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">first_bracket</span><span class="o">-</span><span class="mi">400</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="n">second_bracket</span>
        <span class="n">dy</span> <span class="o">=</span> <span class="mi">200</span> <span class="o">*</span> <span class="n">second_bracket</span>
        <span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">dx</span>
        <span class="n">grad</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">dy</span>

    <span class="k">return</span> <span class="n">obj</span>

<span class="o">%</span><span class="k">timeit</span> -n 1000 res = simplenlopt.minimize(rosenbrock_nlopt_style, x0, jac = &#39;nlopt&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2.14 ms ± 13.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</pre></div></div>
</div>
<p>The in-place replacement led to another small performance gain. Side note: while the if statement might seem weird and unnecessary, it is required for some of the optimizers, so you are on the safe side if you include it in your objective function .</p>
</div>
<div class="section" id="jac-=-‘3-point’/‘2-point’">
<h2>jac = ‘3-point’/‘2-point’<a class="headerlink" href="#jac-=-‘3-point’/‘2-point’" title="Permalink to this headline">¶</a></h2>
<p>These flags tell simplenlopt which finite difference scheme to use. Finite differencing is borrowed from <a class="reference external" href="https://github.com/scipy/scipy/blob/v1.6.3/scipy/optimize/_numdiff.py">SciPy</a>. Note that ‘2-point’ requires less function evaluations but is less precise and therefore more prone to cause optimization failures.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">timeit</span> -n 100 res = simplenlopt.minimize(rosenbrock, x0, jac = &#39;3-point&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
7.39 ms ± 245 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
</pre></div></div>
</div>
<p>This example shows that finite differences are not competitive against analytical gradients. For simple cases such as low dimensional curve fitting they are often still useful. If possible, automatic differentiation represents a powerful alternative.</p>
</div>
<div class="section" id="Autodiff">
<h2>Autodiff<a class="headerlink" href="#Autodiff" title="Permalink to this headline">¶</a></h2>
<p>In recent years, automatic differentiation (autodiff) has become one of the building blocks of machine learning. Many frameworks such as pytorch and tensorflow actually are centered around autodiff. Here, we will use the slightly older <a class="reference external" href="https://github.com/hips/autograd">autograd</a> package to automatigally compute the gradient for us and feed it to simplenlopt.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">autograd.numpy</span> <span class="k">as</span> <span class="nn">anp</span>
<span class="kn">from</span> <span class="nn">autograd</span> <span class="kn">import</span> <span class="n">value_and_grad</span>

<span class="n">rosen_and_grad</span> <span class="o">=</span> <span class="n">value_and_grad</span><span class="p">(</span><span class="n">rosenbrock</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> -n 10 res = simplenlopt.minimize(rosen_and_grad, x0, jac = True)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
17.3 ms ± 392 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
</pre></div></div>
</div>
<p>While autograd results in the worst performance for this example, autodiff shines when it comes to high dimensional problems where the inaccuracies of finite differences are much more severe. To circumvent autograd’s performance issues, another candidate could be for example autograd’s succesor <a class="reference external" href="https://github.com/google/jax">jax</a> which additionally provides just-in-time compilation.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="Curve_Fitting.html" class="btn btn-neutral float-right" title="Curve Fitting" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="Global_Opt.html" class="btn btn-neutral float-left" title="Global Optimization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Daniel Schmitz.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>